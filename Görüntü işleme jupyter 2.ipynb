{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesne Tespiti \n",
    "Genel olarak burda yazılı olan kodlar başka kodların kısımlarını içermektedir çalıştırılması için pazı parametrelerin değiştirilmesi gerekiyor\n",
    "Örnek olarak sistemde kullanılacak resimlerin isimleri Jüpiter defterinin bulunduğu konumda olamaması nedeniyle imread() komutlarında değişiklik yapılması lazım...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kenar Algılama\n",
    "Kod olarak canny komutunu kullanıyoruz lakin algoritma belirlenmiş olan lodra resminde nehir kısmını da nesne olarak algılıyor\n",
    "Bu sıkıntıyı ortadan kaldırmak için blurring (bulanıklaştırma yöntemi) kullanarak fotoğrafı birazdaha bulanıklaştırıp nehir kısmını nesne muhabbetinden çıkartıyoruz\n",
    "\n",
    "Canny komutunu kullanırken belirli tresholdlar kullanmamız lazım bunları bazı matematiksel işlemler kullanarak low ve high şeklinde 2 kısma ayırıyoruz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resmi içe aktar\n",
    "img = cv2.imread(\"indir.jpeg\", 0)\n",
    "plt.figure(), plt.imshow(img, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "edges = cv2.Canny(image = img, threshold1 = 0, threshold2 = 255)\n",
    "plt.figure(), plt.imshow(edges, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "med_val = np.median(img)\n",
    "print(med_val)\n",
    "\n",
    "low = int(max(0, (1 - 0.33)*med_val))\n",
    "high = int(min(255, (1 + 0.33)*med_val))\n",
    "\n",
    "print(low)\n",
    "print(high)\n",
    "\n",
    "edges = cv2.Canny(image = img, threshold1 = low, threshold2 = high)\n",
    "plt.figure(), plt.imshow(edges, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# blur\n",
    "blurred_img = cv2.blur(img, ksize = (5,5))\n",
    "plt.figure(), plt.imshow(blurred_img, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "med_val = np.median(blurred_img)\n",
    "print(med_val)\n",
    "\n",
    "low = int(max(0, (1 - 0.33)*med_val))\n",
    "high = int(min(255, (1 + 0.33)*med_val))\n",
    "\n",
    "print(low)\n",
    "print(high)\n",
    "\n",
    "edges = cv2.Canny(image = blurred_img, threshold1 = low, threshold2 = high)\n",
    "plt.figure(), plt.imshow(edges, cmap = \"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Köşe Algılama\n",
    "2 çeşit yöntem vardır\n",
    "1-) Harris Corner \n",
    "2-)Shi Tomasi Corner \n",
    "    şeklindedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resmi içe aktar\n",
    "img = cv2.imread(\"sudoku.jpg\", 0)\n",
    "img = np.float32(img)\n",
    "print(img.shape)\n",
    "plt.figure(), plt.imshow(img, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# harris corner detection\n",
    "dst = cv2.cornerHarris(img, blockSize = 2, ksize = 3, k = 0.04)\n",
    "plt.figure(), plt.imshow(dst, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "dst = cv2.dilate(dst, None)\n",
    "img[dst>0.2*dst.max()] = 1\n",
    "plt.figure(), plt.imshow(dst, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# shi tomasi detection\n",
    "img = cv2.imread(\"sudoku.jpg\", 0)\n",
    "img = np.float32(img)\n",
    "# 120 sayısı algılanması istenilen köşe sayısını belirtir\n",
    "corners = cv2.goodFeaturesToTrack(img, 120, 0.01, 10)\n",
    "corners = np.int64(corners)\n",
    "\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img, (x,y),3,(125,125,125),cv2.FILLED)\n",
    "    \n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontur algılama \n",
    "\n",
    "Kontür kısaca aynı renk veya yoğunluğa sahip bütün noktaları birleştiren bir eğri olarakaçılanabilir.\n",
    "Nesne analizi, şekil algılama ve tanımada kolaylık sağlar...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resmi içe aktar\n",
    "img = cv2.imread(\"contour.jpg\",0)\n",
    "plt.figure(), plt.imshow(img, cmap = \"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# farklı sürüm için \n",
    "# image, contours, hierarch = cv2.findContours(img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours, hierarch = cv2.findContours(img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "external_contour = np.zeros(img.shape)\n",
    "internal_contour = np.zeros(img.shape)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    \n",
    "    # external\n",
    "    if hierarch[0][i][3] == -1:\n",
    "        cv2.drawContours(external_contour,contours, i, 255, -1)\n",
    "    else: # internal\n",
    "        cv2.drawContours(internal_contour,contours, i, 255, -1)\n",
    "\n",
    "plt.figure(), plt.imshow(external_contour, cmap = \"gray\"),plt.axis(\"off\")\n",
    "plt.figure(), plt.imshow(internal_contour, cmap = \"gray\"),plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renk ile nesne tespiti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nesne merkezini depolayacak veri tipi\n",
    "buffer_size = 16\n",
    "pts = deque(maxlen = buffer_size)\n",
    "\n",
    "# mavi renk aralığı HSV\n",
    "# mavi renginin hangi tonlarını aralıklarını kullanacaksak onun aralıklarını kısaca eşik aralıklarını ayarlamak için kullanılır...\n",
    "blueLower = (84,  98,  0)\n",
    "blueUpper = (179, 255, 255)\n",
    "\n",
    "# capture\n",
    "# Kullanılacak videonun uzunluğunu genişliğini ayarlar...\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,960)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # genel video okuma ve video'yu okuduğunun feedback'ini görmek için kullanılan kod bloğu\n",
    "    success, imgOriginal = cap.read()\n",
    "    # ve eğer başarılı ise...\n",
    "    if success: \n",
    "        \n",
    "        # blur (gauss bulanıklaştırması)\n",
    "        blurred = cv2.GaussianBlur(imgOriginal, (11,11), 0) \n",
    "        \n",
    "        # hsv\n",
    "        # framenin rengini BGR dan HSV formatina çevirir ki sonrasında kullanabilelim...\n",
    "        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow(\"HSV Image\",hsv)\n",
    "        \n",
    "        # mavi için maske oluştur\n",
    "        # bu kısımda resmimizde mavi olan kısımlar hariç bütün kısımları siyah yapan ama mavi kısımları beyaz yaparak maskeleyen yeni siyah beyaz formatında frameler üretiriz \n",
    "        mask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "        cv2.imshow(\"mask Image\",mask)\n",
    "\n",
    "        # maskenin etrafında kalan gürültüleri sil\n",
    "        # oluşturulan maskelerin etrafındaki gürültüleri silmek için erozyon ve genişleme tekrar kullanılır\n",
    "        mask = cv2.erode(mask, None, iterations = 2)\n",
    "        mask = cv2.dilate(mask, None, iterations = 2)\n",
    "        cv2.imshow(\"Mask + erozyon ve genisleme\",mask)\n",
    "        \n",
    "        # farklı sürüm için\n",
    "        # (_, contours,_) = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # kontur / Kontürleri bulma kısmını burda yapıyoruz\n",
    "        (contours,_) = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(contours)\n",
    "        # şimdilik sadece tanımını yaptığımız daha sonrasında içini dolduracağımız merkez kordinatları için değişken atadık\n",
    "        center = None\n",
    "\n",
    "\n",
    "        # !!!!!!!! Bu kısım sonrasında çok işimize yarayabilir...\n",
    "        # Bu kısım frame nin içinde istenilen renkte herhangi bir cisim olduğu takdirde çalışmasını sağlar yani eğer mavi bir cisim kadraja koyulursa burası çalışır....\n",
    "        if len(contours) > 0:\n",
    "            \n",
    "            # en buyuk konturu al\n",
    "            c = max(contours, key = cv2.contourArea)\n",
    "            \n",
    "            # dikdörtgene çevir \n",
    "            rect = cv2.minAreaRect(c)\n",
    "            \n",
    "            ((x,y), (width,height), rotation) = rect\n",
    "            \n",
    "            s = \"x: {}, y: {}, width: {}, height: {}, rotation: {}\".format(np.round(x),np.round(y),np.round(width),np.round(height),np.round(rotation))\n",
    "            print(s)\n",
    "            \n",
    "            # kutucuk\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int64(box)\n",
    "            \n",
    "            # moment\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"]))\n",
    "            \n",
    "            # konturu çizdir: sarı\n",
    "            cv2.drawContours(imgOriginal, [box], 0, (0,255,255),2)\n",
    "            \n",
    "            # merkere bir tane nokta çizelim: pembe\n",
    "            cv2.circle(imgOriginal, center, 5, (255,0,255),-1)\n",
    "            \n",
    "            # bilgileri ekrana yazdır\n",
    "            cv2.putText(imgOriginal, s, (25,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255,255,255), 2)\n",
    "            \n",
    "            \n",
    "        # deque\n",
    "        pts.appendleft(center)\n",
    "        \n",
    "        for i in range(1, len(pts)):\n",
    "            \n",
    "            if pts[i-1] is None or pts[i] is None: continue\n",
    "        \n",
    "            cv2.line(imgOriginal, pts[i-1], pts[i],(0,255,0),3) # \n",
    "            \n",
    "        cv2.imshow(\"Orijinal Tespit\",imgOriginal)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"): break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şablon eşleme (Template Matching)!!!\n",
    "\n",
    "Şablon eşleştirme, bir görüntünün konumunu daha büyük bir görüntüde aramak ve bulmak için bir yöntemdir.\n",
    "Şablon görüntüsü giriş görüntüsünün altındaki giriş görüntüsünün şablonu ve yamayı karşılaştırır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template matching: sablon esleme\n",
    "\n",
    "img = cv2.imread(\"cat.jpg\", 0)\n",
    "print(img.shape)\n",
    "template = cv2.imread(\"cat_face.jpg\", 0)\n",
    "print(template.shape)\n",
    "h, w = template.shape # height and weight \n",
    "\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for meth in methods:\n",
    "    \n",
    "    method = eval(meth) # 'cv2.TM_CCOEFF' -> cv2.TM_CCOEFF\n",
    "    \n",
    "    res = cv2.matchTemplate(img, template, method)\n",
    "    print(res.shape)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    \n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    cv2.rectangle(img, top_left, bottom_right, 255, 2)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(121), plt.imshow(res, cmap = \"gray\")\n",
    "    plt.title(\"Eşleşen Sonuç\"), plt.axis(\"off\")\n",
    "    plt.subplot(122), plt.imshow(img, cmap = \"gray\")\n",
    "    plt.title(\"Tespit edilen Sonuç\"), plt.axis(\"off\")\n",
    "    plt.suptitle(meth)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Özellik Eşleştirme (Brute-Force)\n",
    "Görüntü işlemede nokta özelliği eşleşmesi, karmaşık bir sahnede belirtilen bir hedefi tespit etmek için bir yöntemdir.\n",
    "Bu yöntem, birden çok nesne yerine tek nesneleri algılar.\n",
    "Örneğin: bu yöntemi kullanarak kişi dağınık bir görüntü üzerinde belirli bir kişiyi tanıyabilir, ancak başka herhangi bir kişiyi tanıyamaz.\n",
    "\n",
    "Brute-Force eşleştiricisi, bir görüntüdeki bir özelliğin tanımlayıcısını başka bir görüntünün diğer tüm özellikleriyle eşleştirir ve mesafeye göre eşleşmeyi döndürür.\n",
    "Tüm özelliklerle eşleşmeyi kontrol ettiği için yavaştır.\n",
    "\n",
    "Ölçek değişmez özellik dönüşümü, anahtar noktaları ilk olarak bir dizi referans görüntüden çıkarılır ve saklanır.\n",
    "Yeni görüntüdeki her bir özelliği bu saklanan veri ile ayrı ayrı karşılaştırarak ve öznitelik vektörlerinin Öklid mesafesine dayalı olarak aday eşleştirme özelliklerini bularak yeni bir görüntüde bir nesne tanınır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ana görüntüyü içe aktar\n",
    "chos = cv2.imread(\"chocolates.jpg\", 0)\n",
    "plt.figure(), plt.imshow(chos, cmap = \"gray\"),plt.axis(\"off\")\n",
    "\n",
    "# aranacak olan görüntü\n",
    "cho = cv2.imread(\"nestle.jpg\", 0)\n",
    "plt.figure(), plt.imshow(cho, cmap = \"gray\"),plt.axis(\"off\")\n",
    "\n",
    "# orb tanımlayıcı\n",
    "# köşe-kenar gbi nesneye ait özellikler\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# anahtar nokta tespiti\n",
    "kp1, des1 = orb.detectAndCompute(cho, None)\n",
    "kp2, des2 = orb.detectAndCompute(chos, None)\n",
    "\n",
    "# bf matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "# noktaları eşleştir\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# mesafeye göre sırala\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "# eşleşen resimleri görselleştirelim\n",
    "plt.figure()\n",
    "img_match = cv2.drawMatches(cho, kp1, chos, kp2, matches[:20], None, flags = 2)\n",
    "plt.imshow(img_match), plt.axis(\"off\"),plt.title(\"orb\")\n",
    "\n",
    "# sift\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# bf\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# anahtar nokta tespiti sift ile\n",
    "kp1, des1 = sift.detectAndCompute(cho, None)\n",
    "kp2, des2 = sift.detectAndCompute(chos, None)\n",
    "\n",
    "matches = bf.knnMatch(des1, des2, k = 2)\n",
    "\n",
    "guzel_eslesme = []\n",
    "\n",
    "for match1, match2 in matches:\n",
    "    \n",
    "    if match1.distance < 0.75*match2.distance:\n",
    "        guzel_eslesme.append([match1])\n",
    "    \n",
    "plt.figure()\n",
    "sift_matches = cv2.drawMatchesKnn(cho,kp1,chos,kp2,guzel_eslesme,None, flags = 2)\n",
    "plt.imshow(sift_matches), plt.axis(\"off\"), plt.title(\"sift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Havza Algoritması\n",
    "Genel olarak belirli renk aralık değişimlerine bağlı olarak kenar bulmaya yarayan Algoritmik yöntemdir... Etkilidir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# içe aktar\n",
    "coin = cv2.imread(\"coins.jpg\")\n",
    "plt.figure(), plt.imshow(coin), plt.axis(\"off\")\n",
    "\n",
    "# lpf: blurring\n",
    "coin_blur = cv2.medianBlur(coin, 13)\n",
    "plt.figure(), plt.imshow(coin_blur), plt.axis(\"off\")\n",
    "\n",
    "# grayscale\n",
    "coin_gray = cv2.cvtColor(coin_blur, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(), plt.imshow(coin_gray, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# binary threshold\n",
    "ret, coin_thresh = cv2.threshold(coin_gray, 75, 255, cv2.THRESH_BINARY)\n",
    "plt.figure(), plt.imshow(coin_thresh, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# kontur\n",
    "# _, contours, hierarchy = cv2.findContours(coin_thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierarchy = cv2.findContours(coin_thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    \n",
    "    if hierarchy[0][i][3] == -1:\n",
    "        cv2.drawContours(coin, contours,i,(0,255,0),10)\n",
    "plt.figure(),plt.imshow(coin),plt.axis(\"off\")\n",
    "\n",
    "# watershed\n",
    "\n",
    "# içe aktar\n",
    "coin = cv2.imread(\"coins.jpg\")\n",
    "plt.figure(), plt.imshow(coin), plt.axis(\"off\")\n",
    "\n",
    "# lpf: blurring\n",
    "coin_blur = cv2.medianBlur(coin, 13)\n",
    "plt.figure(), plt.imshow(coin_blur), plt.axis(\"off\")\n",
    "\n",
    "# grayscale\n",
    "coin_gray = cv2.cvtColor(coin_blur, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(), plt.imshow(coin_gray, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# binary threshold\n",
    "ret, coin_thresh = cv2.threshold(coin_gray, 65, 255, cv2.THRESH_BINARY)\n",
    "plt.figure(), plt.imshow(coin_thresh, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# açılma\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(coin_thresh, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "plt.figure(), plt.imshow(opening, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# nesneler arası distance bulalım\n",
    "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "plt.figure(), plt.imshow(dist_transform, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# resmi küçült\n",
    "ret, sure_foreground = cv2.threshold(dist_transform, 0.4*np.max(dist_transform),255,0)\n",
    "plt.figure(), plt.imshow(sure_foreground, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# arka plan için resmi büyült\n",
    "sure_background = cv2.dilate(opening, kernel, iterations = 1)\n",
    "sure_foreground = np.uint8(sure_foreground)\n",
    "unknown = cv2.subtract(sure_background,sure_foreground)\n",
    "plt.figure(), plt.imshow(unknown, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# bağlantı\n",
    "ret, marker = cv2.connectedComponents(sure_foreground)\n",
    "marker = marker + 1\n",
    "marker[unknown == 255] = 0\n",
    "plt.figure(), plt.imshow(marker, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "# havza\n",
    "marker = cv2.watershed(coin,marker)\n",
    "plt.figure(), plt.imshow(marker, cmap=\"gray\"), plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# kontur\n",
    "# _, contours, hierarchy = cv2.findContours(coin_thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, hierarchy = cv2.findContours(marker.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    \n",
    "    if hierarchy[0][i][3] == -1:\n",
    "        cv2.drawContours(coin, contours,i,(255,0,0),2)\n",
    "plt.figure(),plt.imshow(coin),plt.axis(\"off\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4323cec2d52b922c9f7bbe1804da129109550f4257a94c7360d37c119722165e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
